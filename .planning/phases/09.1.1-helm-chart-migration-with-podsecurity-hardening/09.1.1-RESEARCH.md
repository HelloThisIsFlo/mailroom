# Phase 09.1.1: Helm Chart Migration with PodSecurity Hardening - Research

**Researched:** 2026-03-01
**Domain:** Kubernetes Helm charts, Pod Security Standards
**Confidence:** HIGH

## Summary

This phase converts the existing `k8s/` plain manifests into a Helm chart at `helm/mailroom/` and adds Kubernetes Pod Security Standards (restricted level) hardening. The existing manifests (namespace, deployment, configmap, secret) are well-structured and transfer directly to Helm templates with minimal changes. The main additions are: (1) Helm template parameterization, (2) a pre-install/pre-upgrade hook Job for the `mailroom setup` preflight check, (3) restricted-level PSS namespace labels and pod/container securityContext, and (4) a `secrets-values.yaml` pattern replacing the old `k8s/secret.yaml`.

The Dockerfile already runs as non-root (`USER app`), so PSS restricted compliance is straightforward. The config.yaml is already mounted as a ConfigMap volume at `/app/config.yaml`, and secrets are injected as env vars via `envFrom: secretRef` -- both patterns carry over cleanly to Helm.

**Primary recommendation:** Build the Helm chart by translating each existing k8s manifest into a Helm template, adding securityContext fields for restricted PSS compliance, and implementing the setup Job as a Helm hook. Keep parameterization minimal -- this is a single-user chart.

<user_constraints>
## User Constraints (from CONTEXT.md)

### Locked Decisions
- Secrets delivered via a gitignored `secrets-values.yaml` file, passed with `helm install -f secrets-values.yaml`
- A committed `secrets-values.yaml.example` with placeholder values for onboarding (mirrors current `k8s/secret.yaml.example` pattern)
- Minimal parameterization only: image tag, resource limits/requests, replica count -- this is a single-user service, not a public chart
- No external-secrets operator or manual kubectl secret management
- **Restricted** Pod Security Standard -- strictest Kubernetes level
- Namespace labels: `pod-security.kubernetes.io/enforce: restricted` (reject non-compliant pods at admission)
- Container securityContext: `runAsNonRoot: true`, `allowPrivilegeEscalation: false`, `capabilities: { drop: ["ALL"] }`, `seccompProfile: { type: RuntimeDefault }`
- `readOnlyRootFilesystem: true` with an emptyDir volume mounted at `/tmp` for Python temp files
- Pod-level: `runAsNonRoot: true`, `seccompProfile: { type: RuntimeDefault }`
- Helm Job template included, triggered as a `pre-install` / `pre-upgrade` hook
- Default behavior (dry-run): Job runs `mailroom setup` in dry-run mode -- checks if required Fastmail mailboxes and contact groups exist. If anything is missing, Job exits non-zero, Helm aborts, and the currently deployed version stays running
- Apply override: `--set setup.apply=true` runs setup in apply mode -- provisions missing resources on Fastmail, then deployment proceeds
- Same PodSecurity hardening as the main deployment (same image, same securityContext)
- Delete `k8s/` directory entirely
- Helm chart at `helm/mailroom/` (standard convention for single chart in app repo)
- Update `.gitignore`: remove `k8s/secret.yaml`, add `helm/mailroom/secrets-values.yaml`

### Claude's Discretion
- Config.yaml handling: inline in values.yaml vs separate file (pick what works best with Helm conventions)
- Chart.yaml metadata (version, appVersion, description)
- Template structure and helper naming
- NOTES.txt content (post-install instructions)

### Deferred Ideas (OUT OF SCOPE)
- Cluster migration steps (delete old kubectl-managed resources, helm install) -- operational todo, not in-repo artifact
- CI/CD pipeline for automated deployments -- future consideration
</user_constraints>

## Standard Stack

### Core
| Tool | Version | Purpose | Why Standard |
|------|---------|---------|--------------|
| Helm | 3.x (user's installed version) | Chart packaging and deployment | Industry standard K8s package manager |
| Kubernetes Pod Security Standards | GA since K8s 1.25 | Pod admission control | Built-in, no external tool needed |

### Supporting
| Tool | Purpose | When to Use |
|------|---------|-------------|
| `helm lint` | Validate chart structure | Before committing, catches template errors |
| `helm template` | Render templates locally | Debug/verify generated manifests without a cluster |

### Alternatives Considered
| Instead of | Could Use | Tradeoff |
|------------|-----------|----------|
| Helm chart | Kustomize | Kustomize is overlay-based, no templating -- user decided on Helm |
| Namespace template | `--create-namespace` only | Cannot add PSS labels without a namespace template |
| secrets-values.yaml | external-secrets operator | Over-engineered for single-user service -- user decided against |

## Architecture Patterns

### Recommended Chart Structure
```
helm/mailroom/
  Chart.yaml              # Chart metadata
  values.yaml             # Default values (config.yaml content, resource defaults)
  secrets-values.yaml.example  # Placeholder secrets for onboarding
  templates/
    _helpers.tpl           # Named templates (fullname, labels, selectorLabels, securityContext)
    namespace.yaml         # Namespace with PSS labels
    configmap.yaml         # config.yaml content from values
    secret.yaml            # Secret from secrets-values.yaml
    deployment.yaml        # Main deployment with PSS securityContext
    setup-job.yaml         # Pre-install/pre-upgrade hook Job
    NOTES.txt              # Post-install usage instructions
```

### Pattern 1: Config.yaml Inline in values.yaml
**What:** Embed the full config.yaml content under a `config` key in values.yaml. The ConfigMap template renders it with `toYaml`.
**Why this over a separate file:** Helm's primary mechanism is values.yaml. Keeping config inline means `--set` overrides work, `helm template` renders correctly, and there's a single source of truth. A separate file would require custom handling outside Helm's value pipeline.
**Example:**
```yaml
# values.yaml
config:
  polling:
    interval: 60
    debounce_seconds: 3
  triage:
    screener_mailbox: Screener
    categories:
      - name: Imbox
        destination_mailbox: Inbox
      - Feed
      - Paper Trail
      - Jail
      - name: Person
        parent: Imbox
        contact_type: person
  labels:
    mailroom_error: "@MailroomError"
    mailroom_warning: "@MailroomWarning"
    warnings_enabled: true
  logging:
    level: info
```

```yaml
# templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ include "mailroom.fullname" . }}-config
  namespace: {{ .Release.Namespace }}
  labels:
    {{- include "mailroom.labels" . | nindent 4 }}
data:
  config.yaml: |
    {{- toYaml .Values.config | nindent 4 }}
```

### Pattern 2: PSS-Compliant SecurityContext (Restricted Level)
**What:** Both pod-level and container-level securityContext fields set for restricted PSS compliance.
**Example:**
```yaml
# In _helpers.tpl -- reusable across Deployment and Job
{{- define "mailroom.podSecurityContext" -}}
runAsNonRoot: true
seccompProfile:
  type: RuntimeDefault
{{- end }}

{{- define "mailroom.containerSecurityContext" -}}
runAsNonRoot: true
allowPrivilegeEscalation: false
readOnlyRootFilesystem: true
seccompProfile:
  type: RuntimeDefault
capabilities:
  drop:
    - ALL
{{- end }}
```

### Pattern 3: Setup Job as Helm Hook
**What:** A Kubernetes Job that runs `mailroom setup` before install/upgrade. Default is dry-run (validation only); `--set setup.apply=true` enables provisioning.
**Key annotations:**
```yaml
annotations:
  "helm.sh/hook": pre-install,pre-upgrade
  "helm.sh/hook-weight": "-5"
  "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
```
**How it works:**
- `pre-install,pre-upgrade`: Runs before every install and upgrade
- `hook-weight: "-5"`: Runs early (before any weight-0 hooks)
- `hook-delete-policy: before-hook-creation,hook-succeeded`: Cleans up previous Job before creating new one, and removes successful Job after completion
- Helm **waits** for Job completion -- if the Job exits non-zero, the install/upgrade is aborted
- `backoffLimit: 0` + `restartPolicy: Never`: Fail fast, don't retry (the user should fix config or re-run with `setup.apply=true`)

**Command construction:**
```yaml
command: ["mailroom", "setup"]
{{- if .Values.setup.apply }}
args: ["--apply"]
{{- end }}
```

### Pattern 4: Namespace with PSS Labels
**What:** Include a namespace template in the chart with Pod Security Standards enforcement labels.
**Why template instead of just `--create-namespace`:** `--create-namespace` creates a bare namespace without labels. We need PSS enforcement labels, which can only be set via a namespace resource definition.
**Trade-off:** Including a namespace template means `helm install` should use `-n mailroom` (matching the template) but NOT `--create-namespace` (which would conflict). On `helm upgrade`, Helm applies the namespace resource as an update.
**Example:**
```yaml
# templates/namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: {{ .Release.Namespace }}
  labels:
    {{- include "mailroom.labels" . | nindent 4 }}
    pod-security.kubernetes.io/enforce: restricted
    pod-security.kubernetes.io/enforce-version: latest
    pod-security.kubernetes.io/warn: restricted
    pod-security.kubernetes.io/warn-version: latest
    pod-security.kubernetes.io/audit: restricted
    pod-security.kubernetes.io/audit-version: latest
```

### Pattern 5: Secrets via Values File
**What:** Secrets provided through a gitignored `secrets-values.yaml`, injected as a Kubernetes Secret, referenced via `envFrom`.
**Example:**
```yaml
# secrets-values.yaml.example
secrets:
  jmap_token: "your-fastmail-jmap-token-here"
  carddav_username: "your-fastmail-email@fastmail.com"
  carddav_password: "your-fastmail-app-password-here"
```
```yaml
# templates/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: {{ include "mailroom.fullname" . }}-secrets
  namespace: {{ .Release.Namespace }}
  labels:
    {{- include "mailroom.labels" . | nindent 4 }}
type: Opaque
stringData:
  MAILROOM_JMAP_TOKEN: {{ .Values.secrets.jmap_token | quote }}
  MAILROOM_CARDDAV_USERNAME: {{ .Values.secrets.carddav_username | quote }}
  MAILROOM_CARDDAV_PASSWORD: {{ .Values.secrets.carddav_password | quote }}
```

### Anti-Patterns to Avoid
- **Hardcoding namespace in every template metadata:** Use `{{ .Release.Namespace }}` consistently, never hardcode `mailroom`
- **Over-parameterizing values.yaml:** This is a single-user chart -- don't add toggles for every field. Keep it minimal: image tag, resources, replica count, setup.apply
- **Putting secrets in values.yaml:** Secrets go in the gitignored `secrets-values.yaml`, never in the committed `values.yaml`
- **Skipping `readOnlyRootFilesystem` emptyDir mount:** Python writes to `/tmp` -- without the emptyDir mount, the container will crash with read-only root

## Don't Hand-Roll

| Problem | Don't Build | Use Instead | Why |
|---------|-------------|-------------|-----|
| Pre-deploy validation | Custom script outside Helm | Helm hook (pre-install/pre-upgrade Job) | Helm manages lifecycle, waits for completion, aborts on failure |
| Namespace PSS enforcement | kubectl label script | Namespace template with labels | Declarative, version-controlled, applied with chart |
| SecurityContext boilerplate | Copy-paste across Deployment and Job | `_helpers.tpl` named templates | DRY, consistent between Deployment and Job |
| Secret management | kubectl create secret | `secrets-values.yaml` + Secret template | Helm manages the Secret lifecycle |

**Key insight:** Helm's hook mechanism is the right abstraction for the setup preflight check. It integrates with the install/upgrade lifecycle, blocks on failure, and uses the same image/securityContext as the main deployment.

## Common Pitfalls

### Pitfall 1: Namespace Conflict with --create-namespace
**What goes wrong:** Using both a namespace template AND `--create-namespace` flag causes "already exists" errors or creates a bare namespace without PSS labels.
**Why it happens:** `--create-namespace` creates the namespace before templates are applied. Then the namespace template tries to create it again.
**How to avoid:** Use `helm install -n mailroom` WITHOUT `--create-namespace`. The namespace template in the chart creates it with the correct labels. Document this in NOTES.txt.
**Warning signs:** Install fails with "namespace already exists" or namespace lacks PSS labels.

### Pitfall 2: readOnlyRootFilesystem Without /tmp Mount
**What goes wrong:** Python's `tempfile` module writes to `/tmp`. With `readOnlyRootFilesystem: true` and no writable `/tmp`, the container crashes.
**Why it happens:** Easy to forget that Python implicitly uses `/tmp` for various operations (tempfile, some library caches).
**How to avoid:** Always pair `readOnlyRootFilesystem: true` with an `emptyDir` volume mounted at `/tmp`.
**Warning signs:** Container CrashLoopBackOff with "Read-only file system" errors.

### Pitfall 3: Hook Job Missing Same SecurityContext
**What goes wrong:** The setup Job Pod gets rejected by PSS admission because it lacks the restricted-level securityContext.
**Why it happens:** Hook templates are often written as an afterthought without the same securityContext as the main deployment.
**How to avoid:** Use shared `_helpers.tpl` templates for securityContext so both Deployment and Job use identical settings.
**Warning signs:** `helm install` fails with PSS admission errors mentioning the hook Job.

### Pitfall 4: Config.yaml Mount Path with readOnlyRootFilesystem
**What goes wrong:** The config.yaml is mounted at `/app/config.yaml` with `subPath` and `readOnly: true`. This is fine with `readOnlyRootFilesystem` because volume mounts overlay the read-only root.
**Why it happens:** Confusion about whether volume mounts are affected by `readOnlyRootFilesystem`.
**How to avoid:** Volume mounts are independent of `readOnlyRootFilesystem`. The config volume mount works as-is. No changes needed.
**Warning signs:** None -- this is a non-issue, just documenting to prevent unnecessary debugging.

### Pitfall 5: Hook Job backoffLimit Default
**What goes wrong:** If `backoffLimit` is not set, Kubernetes defaults to 6 retries. A failing setup dry-run retries 6 times before Helm gives up.
**Why it happens:** Kubernetes Job default `backoffLimit` is 6.
**How to avoid:** Explicitly set `backoffLimit: 0` on the setup Job -- fail fast, let the user fix and re-run.
**Warning signs:** Slow failure -- Helm hangs for minutes waiting for retries.

### Pitfall 6: MAILROOM_CONFIG Env Var Path in Container
**What goes wrong:** The app resolves config.yaml via `MAILROOM_CONFIG` env var or defaults to `config.yaml` (relative to cwd). In the container, the working directory is not explicitly set, but the config is mounted at `/app/config.yaml`.
**Why it happens:** The Dockerfile sets `WORKDIR /app` only in the builder stage. The runtime stage inherits the default `/` working directory.
**How to avoid:** Either set `MAILROOM_CONFIG=/app/config.yaml` as an env var in the Deployment, or ensure the container's working directory is `/app`. The current deployment works because the volume mount is at `/app/config.yaml` and the existing deployment sets no explicit workdir, so check this works. Safest: set `MAILROOM_CONFIG` env var explicitly.
**Warning signs:** "Config file not found" error on startup.

## Code Examples

### Complete values.yaml Structure
```yaml
# -- Image configuration
image:
  repository: ghcr.io/hellothisisflo/mailroom
  tag: latest
  pullPolicy: Always

# -- Number of replicas (single-instance service)
replicaCount: 1

# -- Resource limits and requests
resources:
  requests:
    memory: "64Mi"
    cpu: "100m"
  limits:
    memory: "128Mi"
    cpu: "100m"

# -- Setup Job configuration
setup:
  # -- Run setup in apply mode (provisions missing resources on Fastmail)
  apply: false

# -- Application configuration (becomes config.yaml in ConfigMap)
config:
  polling:
    interval: 60
    debounce_seconds: 3
  triage:
    screener_mailbox: Screener
    categories:
      - name: Imbox
        destination_mailbox: Inbox
      - Feed
      - Paper Trail
      - Jail
      - name: Person
        parent: Imbox
        contact_type: person
  labels:
    mailroom_error: "@MailroomError"
    mailroom_warning: "@MailroomWarning"
    warnings_enabled: true
  logging:
    level: info

# -- Secrets (provide via secrets-values.yaml, NOT here)
secrets:
  jmap_token: ""
  carddav_username: ""
  carddav_password: ""
```

### Complete _helpers.tpl
```yaml
{{/*
Expand the name of the chart.
*/}}
{{- define "mailroom.name" -}}
{{- default .Chart.Name .Values.nameOverride | trunc 63 | trimSuffix "-" }}
{{- end }}

{{/*
Create a default fully qualified app name.
*/}}
{{- define "mailroom.fullname" -}}
{{- if .Values.fullnameOverride }}
{{- .Values.fullnameOverride | trunc 63 | trimSuffix "-" }}
{{- else }}
{{- $name := default .Chart.Name .Values.nameOverride }}
{{- if contains $name .Release.Name }}
{{- .Release.Name | trunc 63 | trimSuffix "-" }}
{{- else }}
{{- printf "%s-%s" .Release.Name $name | trunc 63 | trimSuffix "-" }}
{{- end }}
{{- end }}
{{- end }}

{{/*
Common labels
*/}}
{{- define "mailroom.labels" -}}
helm.sh/chart: {{ include "mailroom.chart" . }}
{{ include "mailroom.selectorLabels" . }}
app.kubernetes.io/version: {{ .Chart.AppVersion | quote }}
app.kubernetes.io/managed-by: {{ .Release.Service }}
{{- end }}

{{/*
Selector labels
*/}}
{{- define "mailroom.selectorLabels" -}}
app.kubernetes.io/name: {{ include "mailroom.name" . }}
app.kubernetes.io/instance: {{ .Release.Name }}
{{- end }}

{{/*
Chart label
*/}}
{{- define "mailroom.chart" -}}
{{- printf "%s-%s" .Chart.Name .Chart.Version | replace "+" "_" | trunc 63 | trimSuffix "-" }}
{{- end }}

{{/*
Pod-level security context (restricted PSS)
*/}}
{{- define "mailroom.podSecurityContext" -}}
runAsNonRoot: true
seccompProfile:
  type: RuntimeDefault
{{- end }}

{{/*
Container-level security context (restricted PSS)
*/}}
{{- define "mailroom.containerSecurityContext" -}}
runAsNonRoot: true
allowPrivilegeEscalation: false
readOnlyRootFilesystem: true
seccompProfile:
  type: RuntimeDefault
capabilities:
  drop:
    - ALL
{{- end }}
```

### Setup Job Template
```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: {{ include "mailroom.fullname" . }}-setup
  namespace: {{ .Release.Namespace }}
  labels:
    {{- include "mailroom.labels" . | nindent 4 }}
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade
    "helm.sh/hook-weight": "-5"
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
spec:
  backoffLimit: 0
  template:
    metadata:
      labels:
        {{- include "mailroom.selectorLabels" . | nindent 8 }}
    spec:
      restartPolicy: Never
      securityContext:
        {{- include "mailroom.podSecurityContext" . | nindent 8 }}
      containers:
        - name: setup
          image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
          command: ["mailroom", "setup"]
          {{- if .Values.setup.apply }}
          args: ["--apply"]
          {{- end }}
          env:
            - name: MAILROOM_CONFIG
              value: /app/config.yaml
          envFrom:
            - secretRef:
                name: {{ include "mailroom.fullname" . }}-secrets
          volumeMounts:
            - name: config
              mountPath: /app/config.yaml
              subPath: config.yaml
              readOnly: true
            - name: tmp
              mountPath: /tmp
          securityContext:
            {{- include "mailroom.containerSecurityContext" . | nindent 12 }}
          resources:
            {{- toYaml .Values.resources | nindent 12 }}
      volumes:
        - name: config
          configMap:
            name: {{ include "mailroom.fullname" . }}-config
        - name: tmp
          emptyDir: {}
```

### NOTES.txt Content
```
Mailroom has been deployed to namespace {{ .Release.Namespace }}.

{{- if not .Values.setup.apply }}
The setup preflight check ran in dry-run mode.
If it failed, either fix your config or re-deploy with:
  helm upgrade {{ .Release.Name }} helm/mailroom/ -n {{ .Release.Namespace }} \
    -f secrets-values.yaml --set setup.apply=true
{{- else }}
Setup ran in apply mode -- Fastmail resources have been provisioned.
{{- end }}

Check status:
  kubectl get pods -n {{ .Release.Namespace }}
  kubectl logs -n {{ .Release.Namespace }} deploy/{{ include "mailroom.fullname" . }}
```

## State of the Art

| Old Approach | Current Approach | When Changed | Impact |
|--------------|------------------|--------------|--------|
| PodSecurityPolicy (PSP) | Pod Security Standards (PSS) via namespace labels | K8s 1.25 GA (Aug 2022) | PSP removed; PSS is built-in, label-based |
| `kubectl apply -f k8s/` | `helm install/upgrade` | This phase | Single deployment method, lifecycle management |
| Manual secret creation | `secrets-values.yaml` passed to Helm | This phase | Secret lifecycle managed by Helm |

**Deprecated/outdated:**
- PodSecurityPolicy: Removed in K8s 1.25. Pod Security Standards (namespace labels + admission controller) is the replacement.
- Helm 2 (Tiller): Long deprecated. Helm 3 is the standard.

## Open Questions

1. **Dockerfile runtime WORKDIR**
   - What we know: The builder stage has `WORKDIR /app`, but the runtime stage does not explicitly set WORKDIR. Config is mounted at `/app/config.yaml`.
   - What's unclear: Whether the runtime container's cwd is `/` or `/app`. The `USER app` directive sets home to `/app` (via `useradd -d /app`), but that doesn't set cwd.
   - Recommendation: Set `MAILROOM_CONFIG=/app/config.yaml` explicitly in the Deployment env vars to be safe. This is already a supported pattern (Phase 9.1 added this env var).

2. **UID for runAsUser**
   - What we know: The Dockerfile uses `useradd -r -d /app -g app -N app` without an explicit `-u` flag. The assigned UID depends on the base image.
   - What's unclear: The exact UID of the `app` user in the container.
   - Recommendation: Don't set `runAsUser` in the securityContext. `runAsNonRoot: true` is sufficient -- it validates the container user is non-root at admission time. The Dockerfile's `USER app` already ensures this. Setting a specific `runAsUser` would be fragile if the base image changes.

## Sources

### Primary (HIGH confidence)
- [Helm official docs - Chart Hooks](https://helm.sh/docs/topics/charts_hooks/) - Hook annotations, lifecycle, delete policies
- [Helm official docs - Chart Structure](https://helm.sh/docs/topics/charts/) - Directory layout, file conventions
- [Helm official docs - Named Templates](https://helm.sh/docs/chart_template_guide/named_templates/) - _helpers.tpl patterns
- [Helm official docs - Best Practices: Templates](https://helm.sh/docs/chart_best_practices/templates/) - File naming, namespacing
- [Kubernetes Pod Security Standards](https://kubernetes.io/docs/concepts/security/pod-security-standards/) - Restricted level field requirements
- [Kubernetes - Enforce PSS with Namespace Labels](https://kubernetes.io/docs/tasks/configure-pod-container/enforce-standards-namespace-labels/) - Label format and values
- Context7 `/websites/helm_sh` - Chart hooks, named templates, chart structure

### Secondary (MEDIUM confidence)
- [Helm GitHub Issue #5153](https://github.com/helm/helm/issues/5153) - Namespace template vs --create-namespace conflict
- [Helm GitHub Issue #11448](https://github.com/helm/helm/issues/11448) - Namespace label management
- [LSST Phalanx docs](https://phalanx.lsst.io/developers/helm-chart/container-tmp.html) - readOnlyRootFilesystem + /tmp emptyDir pattern

### Tertiary (LOW confidence)
- None -- all findings verified against primary sources

## Metadata

**Confidence breakdown:**
- Standard stack: HIGH - Helm 3 and PSS are well-documented, stable APIs
- Architecture: HIGH - Patterns verified against Helm official docs and Context7
- Pitfalls: HIGH - Common issues well-documented in Kubernetes and Helm communities

**Research date:** 2026-03-01
**Valid until:** 2026-04-01 (stable domain, 30-day validity)
